{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c0341437",
      "metadata": {
        "id": "c0341437"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02cf8f5a",
      "metadata": {
        "id": "02cf8f5a"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "    <p><strong>NOTE:</strong></p>\n",
        "    <ol>\n",
        "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
        "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
        "    </ol>\n",
        "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE HERE</TT></strong>\" or \"<strong><TT>YOUR ANSWER HERE</TT></strong>\".</p>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    <h3 style=\"text-decoration:underline;\">Version 2: Changes</h3>\n",
        "    <p>Please view the blue bubbles (similar to the one encapsulating this text) with the heading <strong>Update</strong> for revised instructions, clarifications, or added details.</p>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This task involves **classification**.\n",
        "\n",
        "You will classify a set of images using simple implementations of classifiers (linear, SVM, and decision tree classifiers) and an ensemble of the three classifiers. Each image will consist of either a cat or a dog. The classifier must correctly label each image as either an image of a *cat* or as an image of a *dog*.\n",
        "![alt text](https://storage.googleapis.com/tfds-data/visualization/fig/cats_vs_dogs-4.0.0.png \"Dogs & Cats Image\")\n",
        "\n",
        "We will then create a more diverse and obfuscated set of test images to evaluate the robustness of the models. Such an obfuscated image could appear as follows:\n",
        "\n",
        "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_tEfd00rr0j8Z_0.png \"DeepDreamed Image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5027f1e2",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ddc11c4abc3e7cf9e415ca656705eb50",
          "grade": false,
          "grade_id": "cell-b9d7b5373c1ab669",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "toc-hr-collapsed": true,
        "id": "5027f1e2"
      },
      "source": [
        "# Preliminaries & Dependencies\n",
        "\n",
        "You will need to install the following **Python** packages to run\n",
        "\n",
        "    pip install matplotlib numpy\n",
        "    pip install sklearn\n",
        "    pip install tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c00f942",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cca651a8bf794cacbcc322b3e4e512a0",
          "grade": false,
          "grade_id": "Overview",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4c00f942"
      },
      "source": [
        "# Overview\n",
        "\n",
        "We want to determine the difference in a model's performance when evaluated with data that has been altered or obfusctaed to make the task more difficult to perform.\n",
        "\n",
        "The theme is *composition* (\"*the principle of progressive disclosure of complexity*\", to borrow from [Keras](https://keras.io/about)). We will extend and build upon the ideas we have previously explored.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc332503",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d4f10ac6675668baaca00f0ff9b80972",
          "grade": false,
          "grade_id": "Objectives",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fc332503"
      },
      "source": [
        "# Objectives\n",
        "\n",
        "Access a *real-world* dataset (e.g., used in kaggle.com competitions, etc.) rather than a *toy* dataset.\n",
        "\n",
        "Generate data from existing, actual data (contrast this to generating synthetic data).\n",
        "\n",
        "Download and implement already trained models.\n",
        "\n",
        "Evaluate the robustness of a model by testing it on data that is designed to be more *complex* than the training data.\n",
        "\n",
        "Develop and evaluate ensembles of models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd2a2a4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "12797154a7dcda9bbc6ac47d61775eb6",
          "grade": false,
          "grade_id": "Data",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ebd2a2a4"
      },
      "source": [
        "# Acquire Data\n",
        "\n",
        "We will use the [Cats and Dogs dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) (size: 786.7 Mb).\n",
        "The dataset consists of images (the input) and labels, either *cat* or *dog* (the output).\n",
        "Information on the dataset is [here](https://www.microsoft.com/en-us/download/details.aspx?id=54765).\n",
        "\n",
        "Our **goal** is to predict which of two labels (*cat* or *dog*) to apply to an image. This is a binary classification task (i.e., *two categories, two labels, two classes*, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ba66f6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "873eb047604372789dd6723cb7ffb846",
          "grade": false,
          "grade_id": "DownloadingData",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c5ba66f6"
      },
      "source": [
        "Downlading a dataset (https://www.tensorflow.org/tutorials/images/data_augmentation#apply_augmentation_to_a_dataset):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fd3f8e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "233697475c6eb1385e500db32ba7f4e8",
          "grade": false,
          "grade_id": "cell-e638479ac5283c7b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "09fd3f8e"
      },
      "outputs": [],
      "source": [
        "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "f, y = (features, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2acdacc0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d127515fa990cd881df1c91c9e0b8e24",
          "grade": false,
          "grade_id": "DataAugmentation",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "toc-hr-collapsed": true,
        "id": "2acdacc0"
      },
      "source": [
        "# Transforming Data\n",
        "\n",
        "We will essentially **augment** our dataset. Augmenting data \"*increases the diversity of your training set by applying random (but realistic) transformations such as image rotation*\" (https://www.tensorflow.org/tutorials/images/data_augmentation).\n",
        "\n",
        "In our case we are *not* augmenting the data to collect more diverse **training data** but to *evaluate* the models on more diverse/complex **testing data**. Thus we will **only** transform the **test data**.\n",
        "\n",
        "\n",
        "\n",
        "## Examples Of Data Augmentation\n",
        "\n",
        "We will be doing something similar to:\n",
        "https://www.tensorflow.org/datasets/catalog/moving_mnist\n",
        "where the MNIST hadwritten digit image dataset was transformed into a video of animated/moving handwritten digits (click *Display Examples* to view the videos).\n",
        "\n",
        "Augmenting a dataset of flower images:\n",
        "https://www.tensorflow.org/tutorials/images/data_augmentation#using_tfimage\n",
        "which uses warping and colour transformations on flower pictures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eae8174d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c6ac6bd2e3560eccbd010d5f886a348f",
          "grade": false,
          "grade_id": "TransformDataset",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eae8174d"
      },
      "source": [
        "## Example Image Transformations\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>NOTE</h4>\n",
        "    This resize_and_rescale function example is provided for your information. We will <strong>not</strong> be using the code in this example.\n",
        "</div>\n",
        "\n",
        "The code (taken from **Tensorflow**'s explanation for [transforming an image dataset](https://www.tensorflow.org/tutorials/images/data_augmentation#apply_augmentation_to_a_dataset)) is to show how simple the image processing step is.\n",
        "\n",
        "\n",
        "Create a function that resizes and rescales the images (so as to \"*unify the size and scale of images in the dataset*\"):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6daebc59",
      "metadata": {
        "id": "6daebc59"
      },
      "outputs": [],
      "source": [
        "def resize_and_rescale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = (image / 255.0)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a136d4c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fd6950c0f3a04ab2ffb5b4d02dede25e",
          "grade": false,
          "grade_id": "cell-2a1dfe409d1ddfd7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6a136d4c"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "    <h4>NOTE</h4>\n",
        "    This example (the augment function) is provided for your information. We will <strong>not</strong> be using the code in this example.\n",
        "</div>\n",
        "\n",
        "Create an *augment* function that applies random transformations to an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea13b6c",
      "metadata": {
        "id": "7ea13b6c"
      },
      "outputs": [],
      "source": [
        "def augment(image_label, seed):\n",
        "    image, label = image_label\n",
        "    image, label = resize_and_rescale(image, label)\n",
        "    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n",
        "    \n",
        "    # Make a new seed\n",
        "    new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
        "    \n",
        "    # Random crop back to the original size\n",
        "    image = tf.image.stateless_random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
        "    \n",
        "    # Random brightness\n",
        "    image = tf.image.stateless_random_brightness(image, max_delta=0.5, seed=new_seed)\n",
        "    \n",
        "    image = tf.clip_by_value(image, 0, 1)\n",
        "    \n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b68b63",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5e44869991b09d69e03045454176bdde",
          "grade": false,
          "grade_id": "StylisticAugment",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "toc-hr-collapsed": true,
        "id": "80b68b63"
      },
      "source": [
        "# Stylistic Transformation\n",
        "\n",
        "We will transform the image data *stylistically* by processing images with [**DeepDream**](https://www.tensorflow.org/tutorials/generative/deepdream).\n",
        "\n",
        "For example, this image of a labrador:\n",
        "\n",
        "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_Y5BPgc8NNbG0_0.png \"Original Image\")\n",
        "\n",
        "transforms into the following image after being processed by **DeepDream**:\n",
        "\n",
        "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_tEfd00rr0j8Z_0.png \"DeepDreamed Image\")\n",
        "\n",
        "A description and tutorial implementation of **Deep Dream** (aka **Inceptionism**) is [here](https://www.tensorflow.org/tutorials/generative/deepdream). Another type of transformation we could have applied to the images was a [Style Transfer](https://www.tensorflow.org/tutorials/generative/style_transfer).\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>NOTE</h4>\n",
        "    We are <strong>not</strong> concerned with the details of <strong>DeepDream</strong>. We will use it as an off-the-shelf component in our system to augment our image dataset for evaluating how a model performs on the <strong>DeepDreamed</strong> images.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dfed4df",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7404e48fd55da7bb62197e29f30bda96",
          "grade": false,
          "grade_id": "Imports",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0dfed4df"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "    <h4>Code To Execute Begins Here</h4>\n",
        "</div>\n",
        "\n",
        "## Imports\n",
        "\n",
        "Import the following libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd52ae1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "831809e6d9d91e7666eac7ddc4b87c4f",
          "grade": false,
          "grade_id": "ImportsCode",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dfd52ae1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import IPython.display as display\n",
        "import PIL.Image\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc14f2ae",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "63747e754e2ac8b13fb86ef03aef9d64",
          "grade": false,
          "grade_id": "DeepDream-ImagePrep",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fc14f2ae"
      },
      "source": [
        "## Image Preparation\n",
        "\n",
        "**DeepDream**'s image preparation (code is from https://www.tensorflow.org/tutorials/generative/deepdream#choose_an_image_to_dream-ify):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e11e687",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "81ae6ae22ce3d8015a74e22d24962889",
          "grade": false,
          "grade_id": "DeepDream-ImagePrepCode",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9e11e687"
      },
      "outputs": [],
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "def download(url, max_dim=None):\n",
        "    name = url.split('/')[-1]\n",
        "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "    img = PIL.Image.open(image_path)\n",
        "    if max_dim:\n",
        "        img.thumbnail((max_dim, max_dim))\n",
        "    return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "    img = 255*(img + 1.0)/2.0\n",
        "    return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Display an image\n",
        "def show(img):\n",
        "    display.display(PIL.Image.fromarray(np.array(img)))\n",
        "\n",
        "# image we will process\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
        "\n",
        "# Downsizing the image makes it easier to work with.\n",
        "original_img = download(url, max_dim=500)\n",
        "show(original_img)\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69fd13f4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fadaf26630924189972d51e2d9735c06",
          "grade": false,
          "grade_id": "DownloadPreTrainedModel",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "69fd13f4"
      },
      "source": [
        "tf.keras.applications.InceptionV3(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a559a7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f915a6c4bb35e048cd7c79a4796a04b7",
          "grade": false,
          "grade_id": "StylisticAugmentDwld",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d5a559a7"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbee512d",
      "metadata": {
        "id": "bbee512d"
      },
      "source": [
        "## Prepare Feature Extraction Model\n",
        "\n",
        "We we do not need to be concerned with the details (we will use the code as it is *off-the-shelf*), but feel free to play with the **layers** to see what effect they have on an image.\n",
        "\n",
        "The explanation of the following code is provided FYI and is taken from https://www.tensorflow.org/tutorials/generative/deepdream#prepare_the_feature_extraction_model.\n",
        "\n",
        "> ...the layers of interest are those where the convolutions are concatenated. There are 11 of these layers in InceptionV3, named 'mixed0' though 'mixed10'. Using different layers will result in different dream-like images. Deeper layers respond to higher-level features (such as eyes and faces), while earlier layers respond to simpler features (such as edges, shapes, and textures). Feel free to experiment with the layers selected below, but keep in mind that deeper layers (those with a higher index) will take longer to train on since the gradient computation is deeper.\n",
        "\n",
        "> The complexity of the features incorporated depends on layers chosen by you, i.e, lower layers produce strokes or simple patterns, while deeper layers give sophisticated features in images, or even whole objects.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f546310",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f35ef390d02bb7e16e30e2676bd7e1a5",
          "grade": false,
          "grade_id": "ChooseLayers",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4f546310"
      },
      "outputs": [],
      "source": [
        "# Maximize the activations of these layers\n",
        "names = ['mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362b90f4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "46e093d6a6cf128d98195341e781389f",
          "grade": false,
          "grade_id": "CalculateLoss",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "362b90f4"
      },
      "source": [
        "## Calculate Loss\n",
        "\n",
        "The following is from https://www.tensorflow.org/tutorials/generative/deepdream#calculate_loss.\n",
        "Again, we aren't concerned with the details and will use the code as it is.\n",
        "\n",
        "> The **loss** is the sum of the activations in the chosen layers. The loss is normalized at each layer so the contribution from larger layers does not outweigh smaller layers. Normally, *loss is a quantity you wish to minimize via gradient descent*. In **DeepDream**, you will *maximize this loss via gradient ascent*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73570b5c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4485731109e26d5d4341a3854875dac6",
          "grade": false,
          "grade_id": "CalculateLoss-Code",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "73570b5c"
      },
      "outputs": [],
      "source": [
        "def calc_loss(img, model):\n",
        "    # Pass forward the image through the model to retrieve the activations.\n",
        "    # Converts the image into a batch of size 1.\n",
        "    img_batch = tf.expand_dims(img, axis=0)\n",
        "    layer_activations = model(img_batch)\n",
        "    if len(layer_activations) == 1:\n",
        "        layer_activations = [layer_activations]\n",
        "\n",
        "    losses = []\n",
        "    for act in layer_activations:\n",
        "        loss = tf.math.reduce_mean(act)\n",
        "        losses.append(loss)\n",
        "\n",
        "    return tf.reduce_sum(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb2b541",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "28d407fcd0ef00d6e14ff3ff24ff1882",
          "grade": false,
          "grade_id": "GradientAscent",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2bb2b541"
      },
      "source": [
        "## Gradient Ascent\n",
        "\n",
        "The following is from https://www.tensorflow.org/tutorials/generative/deepdream#gradient_ascent.\n",
        "Again, we aren't concerned with the details and will use the code as it is.\n",
        "\n",
        "> After the loss for the chosen layers is calculated, calculate the gradients with respect to the image and add them to the original image.\n",
        "Adding the gradients to the image **enhances the patterns seen by the neural network**. At each step, we create an image that **increasingly excites the activations of certain layers** in the network.\n",
        "\n",
        "> The method that does this is wrapped in a `tf.function` for performance. It uses an `input_signature` to ensure that the function is not retraced for different image sizes or `steps/step_size` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d6ba10",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "15ce5cd0af367833ae970f1811fb2f0c",
          "grade": false,
          "grade_id": "DeepDreamCode",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "30d6ba10"
      },
      "outputs": [],
      "source": [
        "class DeepDream(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(\n",
        "        input_signature=(\n",
        "            tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "            tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "    )\n",
        "    def __call__(self, img, steps, step_size):\n",
        "        print(\"Tracing\")\n",
        "        loss = tf.constant(0.0)\n",
        "        for n in tf.range(steps):\n",
        "            with tf.GradientTape() as tape:\n",
        "                # This needs gradients relative to `img`\n",
        "                # `GradientTape` only watches `tf.Variable`s by default\n",
        "                tape.watch(img)\n",
        "                loss = calc_loss(img, self.model)\n",
        "\n",
        "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "            gradients = tape.gradient(loss, img)\n",
        "\n",
        "            # Normalize the gradients.\n",
        "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "            img = img + gradients*step_size\n",
        "            img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "        return loss, img\n",
        "\n",
        "deepdream = DeepDream(dream_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d614078b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4332cee863c5a58cc974a76813813863",
          "grade": false,
          "grade_id": "DeepDream-MainLoop",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d614078b"
      },
      "source": [
        "## DeepDream: Main Loop\n",
        "\n",
        "From https://www.tensorflow.org/tutorials/generative/deepdream#main_loop.\n",
        "Again, we are not concerned with the details and will use the code as it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3c1a84",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ad74e09e3b7a3ef747b532ff20eb526c",
          "grade": false,
          "grade_id": "RunDeepDream",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "ef3c1a84"
      },
      "outputs": [],
      "source": [
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "    # Convert from uint8 to the range expected by the model.\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    img = tf.convert_to_tensor(img)\n",
        "    \n",
        "    step_size = tf.convert_to_tensor(step_size)\n",
        "    steps_remaining = steps\n",
        "    step = 0\n",
        "    \n",
        "    while steps_remaining:\n",
        "        if steps_remaining>100:\n",
        "            run_steps = tf.constant(100)\n",
        "        else:\n",
        "            run_steps = tf.constant(steps_remaining)\n",
        "        steps_remaining -= run_steps\n",
        "        step += run_steps\n",
        "\n",
        "        loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        show(deprocess(img))\n",
        "        print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "    result = deprocess(img)\n",
        "    display.clear_output(wait=True)\n",
        "    show(result)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f9c3c1e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "47ed21463bc12d1778c817055fe4f33e",
          "grade": false,
          "grade_id": "Processing-DeepDream",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3f9c3c1e"
      },
      "source": [
        "Process an image and view the result. This should process the labrador image mentioned earlier and display the **DeepDreamed** image to the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de750be",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3de8eaa86645b3a9b4dca79f0c045ed0",
          "grade": false,
          "grade_id": "cell-251eb7316d8fe070",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7de750be"
      },
      "outputs": [],
      "source": [
        "dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6e110f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a31382d508f051c689173038baced1b9",
          "grade": false,
          "grade_id": "DatasetAnalysis",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "bc6e110f"
      },
      "source": [
        "\n",
        "# Generate New Image Data Via DeepDream"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8440871-2359-47ff-b04b-46412ab48bf8",
      "metadata": {
        "tags": [],
        "id": "e8440871-2359-47ff-b04b-46412ab48bf8"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
        "    <p>The <strong>Cats & Dogs</strong> dataset consists of 20,000 images, which is too many to process by <strong>DeepDream</strong> (as well as taking too long to train the simpler classification models).</br>\n",
        "    Possible approach: use only 1,000 images from the original dataset (800 training, 200 testing).</p>\n",
        "    <p>One method to read the <strong>Cats & Dogs</strong> data is by using the <strong>Tensorflow-Datasets</strong> module:</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4af973d-86cf-40d2-8e59-1828788bb126",
      "metadata": {
        "id": "f4af973d-86cf-40d2-8e59-1828788bb126"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(train_dataset, test_dataset), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fe372c-b43e-4dfd-8d43-44fbd0865ba3",
      "metadata": {
        "tags": [],
        "id": "07fe372c-b43e-4dfd-8d43-44fbd0865ba3"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
        "    <p>Load <strong>Cats & Dogs</strong> dataset, reshape/resize, and save to a new file.</p>\n",
        "    <p><strong>Keras</strong> provides image preprocessing tools we can use.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4a6f44-f78d-4bcd-a398-621fe2030b1d",
      "metadata": {
        "id": "0e4a6f44-f78d-4bcd-a398-621fe2030b1d"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# location of downloaded Dogs vs. Cats image dataset on my computer\n",
        "#folder = '/Volumes/WDBook/dogs-vs-cats/train/'\n",
        "bookmark\n",
        "# subset of original dataset consisting of 1,000 images\n",
        "folder = '/Volumes/WDBook/dogs-vs-cats/train-1000/'\n",
        "\n",
        "# subset of original dataset consisting of 10,000 images\n",
        "#folder = '/Volumes/WDBook/dogs-vs-cats/train-10000/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba30f092-67b6-4d5b-bcfe-83642fcefe0b",
      "metadata": {
        "tags": [],
        "id": "ba30f092-67b6-4d5b-bcfe-83642fcefe0b"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
        "    <p>Because the images in the dataset are of many different dimensions, we will need to resize the images so they are all 200x200 pixels.</br>\n",
        "    This transformation will result in distorting, stretching, etc. every image to conform to a 200x200 image.</p>\n",
        "    <p></p>\n",
        "    <p>Sample code to resize/reshape images:</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c6d1f2-bdea-4ae1-9b5c-b6c364f4484c",
      "metadata": {
        "id": "d9c6d1f2-bdea-4ae1-9b5c-b6c364f4484c"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import load_img\n",
        "# resized_photo = load_img(\"/path/to/original_image_file\", target_size=(200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3fcbd1c-505d-41f8-9495-6629d89c74cf",
      "metadata": {
        "id": "b3fcbd1c-505d-41f8-9495-6629d89c74cf"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
        "    Convert the resized image to a Python array:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5906e8-e252-4293-aed7-42996ffc189f",
      "metadata": {
        "id": "ff5906e8-e252-4293-aed7-42996ffc189f"
      },
      "outputs": [],
      "source": [
        "# resized_photo = img_to_array(resized_photo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d14d53-6329-4ecb-bfdc-3b9744c43c9b",
      "metadata": {
        "tags": [],
        "id": "e1d14d53-6329-4ecb-bfdc-3b9744c43c9b"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
        "    <p>After resizing the images, calculate the amount of memory (RAM) the computer will require to process the entire <strong>Cats & Dogs</strong> image dataset.</p>\n",
        "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 20,000 Images</h4>\n",
        "    <p>Using all <strong>20,000 images</strong> of the original dataset:</br>\n",
        "    20,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
        "     = 2,400,000,000 32-bit pixels</br>\n",
        "     = 76,800,000,000 bits</br>\n",
        "     = 9,600,000,000 bytes (conversion: 8 bits in 1 byte)</br>\n",
        "     = <strong>9.6 Gbytes</strong></p>\n",
        "    <p></br></p>\n",
        "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 1,000 Images</h4>\n",
        "    <p>Using only <strong>1,000 resized images</strong> from the original dataset:</br>\n",
        "    1,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
        "     = 120,000,000 32-bit pixels = 3,840,000,000 bits = 480,000,000 bytes</br>\n",
        "     = <strong>0.48 Gb</strong></p>\n",
        "    <p></br></p>\n",
        "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 10,000 Images</h4>\n",
        "    <p>Using <strong>10,000 resized images</strong> from the original dataset:</br>\n",
        "    10,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
        "     = 1,200,000,000 32-bit pixels = 38,400,000,000 bits = 4,800,000,000 bytes</br>\n",
        "     = <strong>4.8 Gb</strong></p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb1eb97-577f-4148-9419-ee584fb368af",
      "metadata": {
        "tags": [],
        "id": "2fb1eb97-577f-4148-9419-ee584fb368af"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "    <h3 style=\"text-decoration:underline;\">NOTE</h3>\n",
        "    <p>If the dataset is larger than the amount of available <strong>RAM</strong>, then Jupyterlab will display a message similar to:</br>\n",
        "    \"The kernel for A2.ipynb appears to have died. It will restart automatically.\"</p>\n",
        "    <p></p>\n",
        "    Successful execution of the below code will display something similar to:</br>\n",
        "    (1000, 200, 200, 3) (1000,)</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80a52ec-897e-4de2-9690-85edb7a8f5f5",
      "metadata": {
        "id": "b80a52ec-897e-4de2-9690-85edb7a8f5f5"
      },
      "outputs": [],
      "source": [
        "photos, labels = list(), list()\n",
        "\n",
        "# processing every file in a folder\n",
        "for file in listdir(folder):\n",
        "\t# determine label of image from filename (cat = 1, dog = 0)\n",
        "\toutput = 0.0 \n",
        "\tif file.startswith('cat'):\n",
        "\t\toutput = 1.0\n",
        "\t\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "    \n",
        "\t# convert image to a Python array\n",
        "\tphoto = img_to_array(photo)\n",
        "\t\n",
        "    # store converted image & its corresponding output label\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "\n",
        "# converts list of images to a Python array\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "\n",
        "# print(photos.shape, labels.shape)\n",
        "\n",
        "# save resized photos to avoid having to repeat the above process\n",
        "save('/Volumes/WDBook/dogs-vs-cats/dogs_vs_cats_photos.npy', photos)\n",
        "save('/Volumes/WDBook/dogs-vs-cats/dogs_vs_cats_labels.npy', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e43bae4c-5285-4b6f-8615-07a45827729b",
      "metadata": {
        "tags": [],
        "id": "e43bae4c-5285-4b6f-8615-07a45827729b"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
        "    Load the saved reshaped images then confirm their shape (i.e., dimension).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5db3ce-4933-4337-81e7-12e3e85d3421",
      "metadata": {
        "id": "6d5db3ce-4933-4337-81e7-12e3e85d3421"
      },
      "outputs": [],
      "source": [
        "from numpy import load\n",
        "\n",
        "photos = load('/Volumes/WDBook/dogs-vs-cats/dogs_vs_cats_photos.npy')\n",
        "labels = load('/Volumes/WDBook/dogs-vs-cats/dogs_vs_cats_labels.npy')\n",
        "\n",
        "# print(photos.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c78ac98",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0856c4a413ceb3ec832fe982daca7ea2",
          "grade": false,
          "grade_id": "DatasetAnalysisBonus",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6c78ac98"
      },
      "source": [
        "### Analysis Of Dataset\n",
        "\n",
        "Provide empirical information about the Cats & Dogs dataset.\n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "    <h4>BONUS</h4>\n",
        "    Write code to provide empirical information about the <strong>Cats & Dogs</strong> dataset. Use visual elements where possible.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be29a97-bbef-48af-901a-cdb134d7a44b",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bce529bf412a8374518ed3d15a8954c",
          "grade": true,
          "grade_id": "DatasetAnalysisBonus-Code",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "9be29a97-bbef-48af-901a-cdb134d7a44b"
      },
      "source": [
        "The images in the dataset are in multitudes of dimensions, \n",
        "they use different backgrounds, have different contrasts of colors, \n",
        "Some images are blur and hazy\n",
        "\n",
        "![image.png](attachment:20171de2-b037-44a7-b923-8d4ee75fffb2.png)\n",
        "\n",
        "while some are extremely sharp and defined.\n",
        "A weird thing is that some images feature people which I am not sure how it affects the training of the models\n",
        "\n",
        "![image.png](attachment:5e92bca4-ed18-48ad-bf90-5b300d106439.png)\n",
        "![image.png](attachment:8a8e81cd-af1e-43ba-841d-3c810c45f732.png)\n",
        "\n",
        "Some images were overexposed, could work well as a training or testing datasets especially if there was another process like deepdreaming to overexpose the images and test the predcition on them\n",
        "\n",
        "![image.png](attachment:139d1c58-8ed8-4bb1-8114-9790fd6ea368.png)\n",
        "\n",
        "\n",
        "Dogs have less patchy patterns and have consistent colors, which might help the algorithm. Cats however, run a lot of different patterns which can range in a lot of colors. \n",
        "Cats have better defined whiskers as well.\n",
        "\n",
        "![image.png](attachment:81721f9f-5ac6-4cf0-af45-4dede87e3e80.png)\n",
        "![image.png](attachment:3053c9e9-8d58-433f-b719-4e21c1091584.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b0376c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "jp-MarkdownHeadingCollapsed": true,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be88b5263ae9c17e54601494b3cd4964",
          "grade": false,
          "grade_id": "CreateTestTrainDatasets",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "28b0376c"
      },
      "source": [
        "### Create Testing & Training Datasets\n",
        "\n",
        "Separate the **Cats & Dogs** dataset into a test set and a training set.\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code to separate the data into a test set and a training set below.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88451cb5",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb6e26bced217ccddb73b1d7c0ce9ca1",
          "grade": true,
          "grade_id": "cell-CreateTestTrainDatasets",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "88451cb5"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# location of downloaded Dogs vs. Cats image dataset on my computer\n",
        "#folder = '/Volumes/WDBook/dogs-vs-cats/train/'\n",
        "\n",
        "# subset of original dataset consisting of 1,000 images\n",
        "folderCats = 'D:/Development/CMPT 310 CodingQuiz#2/Cats'\n",
        "folderDogs = 'D:/Development/CMPT 310 CodingQuiz#2/Dogs'\n",
        "\n",
        "photos, labels = list(), list()\n",
        "fileNumCats = 0\n",
        "fileNumDogs = 501\n",
        "# processing every file in a folder\n",
        "for file in listdir(folderCats):\n",
        "   \n",
        "    fileStr = str(fileNumCats)\n",
        "   \n",
        "    output = 1.0\n",
        "\n",
        "    photo = load_img(folderCats + '/' + fileStr + '.jpg', target_size=(200, 200))\n",
        "    fileNumCats = fileNumCats+1\n",
        "    \n",
        "    # convert image to a Python array\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    # store converted image & its corresponding output label\n",
        "    photos.append(photo)\n",
        "    labels.append(output)\n",
        "    \n",
        "    \n",
        "for file in listdir(folderDogs):\n",
        "   \n",
        "    fileStr = str(fileNumDogs)\n",
        "\t# determine label of image from filename (cat = 1, dog = 0)\n",
        "    output = 0.0\n",
        "\n",
        "    photo = load_img(folderDogs + '/' + fileStr + '.jpg', target_size=(200, 200))\n",
        "    fileNumDogs = fileNumDogs+1\n",
        "    \n",
        "    # convert image to a Python array\n",
        "    photo = img_to_array(photo)\n",
        "    \n",
        "    # store converted image & its corresponding output label\n",
        "    photos.append(photo)\n",
        "    labels.append(output)\n",
        "\n",
        "# converts list of images to a Python array\n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "\n",
        "\n",
        "# print(photos.shape, labels.shape)\n",
        "\n",
        "# save resized photos to avoid having to repeat the above process\n",
        "save('D:/Development/CMPT 310 Presentation/Images.npy', photos)\n",
        "save('D:/Development/CMPT 310 Presentation/Labels.npy', labels)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "img_train, img_test, label_train, label_test =  train_test_split(photos, labels, test_size=0.2, random_state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb31c1e",
      "metadata": {
        "tags": [],
        "id": "5bb31c1e"
      },
      "source": [
        "### Process Testing Dataset Via DeepDream \n",
        "\n",
        "Create a **DeepDreamed Test Set** by processing the original test set via **DeepDream**. Display a few of the resulting **DeepDreamed** images.\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code that processes images via <strong>DeepDream</strong> below.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3fb66b",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2065e55497478239dd3dcfbb6233b420",
          "grade": true,
          "grade_id": "DeepDreamTheTestSet",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0f3fb66b"
      },
      "outputs": [],
      "source": [
        "# Download an image and read it into a NumPy array.\n",
        "def download(url, max_dim=None):\n",
        "    name = url.split('/')[-1]\n",
        "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "    img = PIL.Image.open(image_path)\n",
        "    if max_dim:\n",
        "        img.thumbnail((max_dim, max_dim))\n",
        "    return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "    img = 255*(img + 1.0)/2.0\n",
        "    return tf.cast(img, tf.uint8)\n",
        "def show(img):\n",
        "    display.display(PIL.Image.fromarray(np.array(img)))\n",
        "    \n",
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
        "\n",
        "# Maximize the activations of these layers\n",
        "names = ['mixed2', 'mixed4']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "def calc_loss(img, model):\n",
        "    # Pass forward the image through the model to retrieve the activations.\n",
        "    # Converts the image into a batch of size 1.\n",
        "    img_batch = tf.expand_dims(img, axis=0)\n",
        "    layer_activations = model(img_batch)\n",
        "    if len(layer_activations) == 1:\n",
        "        layer_activations = [layer_activations]\n",
        "\n",
        "    losses = []\n",
        "    for act in layer_activations:\n",
        "        loss = tf.math.reduce_mean(act)\n",
        "        losses.append(loss)\n",
        "\n",
        "    return tf.reduce_sum(losses)\n",
        "\n",
        "class DeepDream(tf.Module):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    @tf.function(\n",
        "        input_signature=(\n",
        "            tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "            tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "    )\n",
        "    def __call__(self, img, steps, step_size):\n",
        "        print(\"Tracing\")\n",
        "        loss = tf.constant(0.0)\n",
        "        for n in tf.range(steps):\n",
        "            with tf.GradientTape() as tape:\n",
        "                # This needs gradients relative to `img`\n",
        "                # `GradientTape` only watches `tf.Variable`s by default\n",
        "                tape.watch(img)\n",
        "                loss = calc_loss(img, self.model)\n",
        "\n",
        "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "            gradients = tape.gradient(loss, img)\n",
        "\n",
        "            # Normalize the gradients.\n",
        "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "            img = img + gradients*step_size\n",
        "            img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "        return loss, img\n",
        "\n",
        "deepdream = DeepDream(dream_model)\n",
        "\n",
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "    # Convert from uint8 to the range expected by the model.\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    img = tf.convert_to_tensor(img)\n",
        "    \n",
        "    step_size = tf.convert_to_tensor(step_size)\n",
        "    steps_remaining = steps\n",
        "    step = 0\n",
        "    \n",
        "    while steps_remaining:\n",
        "        if steps_remaining>100:\n",
        "            run_steps = tf.constant(100)\n",
        "        else:\n",
        "            run_steps = tf.constant(steps_remaining)\n",
        "        steps_remaining -= run_steps\n",
        "        step += run_steps\n",
        "\n",
        "        loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        show(deprocess(img))\n",
        "        print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "    result = deprocess(img)\n",
        "    display.clear_output(wait=True)\n",
        "    show(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "dream_imgs = list()\n",
        "\n",
        "for x in range(len(img_test)):\n",
        "    dream_img = run_deep_dream_simple(img = img_test[x], steps=100, step_size=0.01)\n",
        "    dream_imgs.append(dream_img)\n",
        "    print(x)\n",
        "    if(x % 50 == 0):\n",
        "        show(dream_img)\n",
        "\n",
        "dream_imgs = asarray(dream_imgs)\n",
        "save(folder + '/' + 'deepDreamed', dream_imgs)\n",
        "    \n",
        "# RAM TO process all the images in subset : 480960000 or 0.48gb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3ac9d5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f5d6c682312f18ccd81b18a0d2d1e011",
          "grade": false,
          "grade_id": "StyleTransfer-BONUS",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4a3ac9d5"
      },
      "source": [
        "### Style Transfer \n",
        "\n",
        "<div class=\"alert alert-success\">\n",
        "    <p>Process the test set using <a href=\"https://www.tensorflow.org/tutorials/generative/style_transfer\">Style Transfer</a>.</p>\n",
        "    <p>Display a few images processed using <strong>Style Transfer</strong>.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fcf81b0-c6c1-4ab6-bffd-387f590157ad",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b3fe8023f152718194f025b12c7b3c6d",
          "grade": true,
          "grade_id": "StyleTransfer-BONUS-code",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6fcf81b0-c6c1-4ab6-bffd-387f590157ad"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "\n",
        "from os import listdir\n",
        "for file in listdir('D:/Development/CMPT 310 Presentation/Style/'):\n",
        "\n",
        "    content_image = load_image('D:/Development/CMPT 310 Presentation/Style/' + file)\n",
        "    style_image = load_image('pattern.jfif')\n",
        "\n",
        "    stylized_image = model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "\n",
        "\n",
        "    plt.imshow(np.squeeze(stylized_image))\n",
        "    plt.show()\n",
        "\n",
        "![image.png](attachment:2453462c-873d-4bfd-98ad-f0a2d04a8079.png)\n",
        "\n",
        "\n",
        "@Inspired from: https://www.youtube.com/watch?v=bFeltWvzZpQ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b8b0f8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "jp-MarkdownHeadingCollapsed": true,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3d97c884d9625a0c0fdbb46e045d9bfc",
          "grade": false,
          "grade_id": "EvaluateSingleModels",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "toc-hr-collapsed": true,
        "id": "45b8b0f8"
      },
      "source": [
        "# Evaluating Individual Models \n",
        "\n",
        "The following classification models are to be evaluated (default parameters can be used in both models):\n",
        "* [SVM classifier](https://scikit-learn.org/stable/modules/svm.html#classification) \n",
        "* [decision tree classifier](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
        "\n",
        "\n",
        "Models will be *trained* on the **training data**.\n",
        "\n",
        "Two *separate evaluations* will be performed:\n",
        "* models will be evaluated on the **original test data**\n",
        "* models will be evaluated on the **transformed test data**\n",
        "\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code below to create and evaluate the classifiers.\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    <h4>TIP</h4>\n",
        "    Classifiers take two arrays as input:</br>\n",
        "    <strong>array X</strong> of shape (number_of_samples, number_of_features) containing the training samples feature data</br>\n",
        "    <strong>array y</strong> of class labels (strings or integers) of shape (number_of_samples)</p>\n",
        "    <p></p>\n",
        "    <p>print(photos.shape, labels.shape)</br>\n",
        "    num_samples = labels.shape[0]</br>\n",
        "    x = np.reshape(photos, (num_samples, -1))</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d3c33d",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b0ab4b4e978cfa368bb6946bcb0abc6a",
          "grade": true,
          "grade_id": "EvaluateSingleModels-Code",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "36d3c33d"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "\n",
        "\n",
        "svm = svm.SVC()\n",
        "\n",
        "print(len(img_test))\n",
        "\n",
        "img_train = img_train.reshape(801,3*200*200)\n",
        "img_test = img_test.reshape(201,3*200*200)\n",
        "\n",
        "svm.fit(img_train,label_train)\n",
        "prediction = svm.predict (img_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(prediction, label_test)\n",
        "#0.5771144278606966\n",
        "\n",
        "Dream = load('D:/Development/CMPT 310 Presentation/deepDreamed.npy')\n",
        "Dream = Dream.reshape(201,3*200*200)\n",
        "predictionDream = svm.predict(Dream)\n",
        "\n",
        "accuracy_score(predictionDream, label_test)\n",
        "#0.46766169154228854\n",
        "\n",
        "#SVM OVER----\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DecTree = DecisionTreeClassifier(random_state=0)\n",
        "DecTree.fit(img_train,label_train)\n",
        "predictionDecTree = DecTree.predict (img_test)\n",
        "#0.4925373134328358\n",
        "accuracy_score(predictionDecTree, label_test)\n",
        "predictionDecTreeDream = DecTree.predict(Dream)\n",
        "accuracy_score(predictionDecTreeDream, label_test)\n",
        "#0.5323383084577115"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9dd782",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0261d7bc7c70261c8965eae920694c06",
          "grade": false,
          "grade_id": "CreateEnsembles",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "toc-hr-collapsed": true,
        "id": "ae9dd782"
      },
      "source": [
        "# Create Ensemble Models\n",
        "\n",
        "View the lecture videos for a *brief* explanation of ensemble models. Scikit-learn provides a [concise explanation of ensembles](https://scikit-learn.org/stable/modules/ensemble.html#ensemble)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c92644",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "95e68b75a06e930660b55690c6c2d8aa",
          "grade": false,
          "grade_id": "CreateRandom",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "84c92644"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "The **scikit-learn** implementation of **Random Forest** \"*combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class*\".\n",
        "\n",
        "Code examples for implementing a **Random Forest Classifiers** are [here](https://scikit-learn.org/stable/modules/ensemble.html#forest).\n",
        "API information on **Random Forest Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier).\n",
        "\n",
        "Using **scikit-learn**, create a **Random Forest** classifier consisting of the following parameters (model parameters not specified can be left to their default values):\n",
        "* number of estimators = 100\n",
        "\n",
        "\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code to create a Random Forest classifier ensemble below.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b8e1c1",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff475a57a607ca0ebb7a51b626905a8b",
          "grade": true,
          "grade_id": "RandomForest-Code",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "53b8e1c1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RandomForest = RandomForestClassifier(n_estimators=100)\n",
        "RandomForest.fit(img_train,label_train)\n",
        "predictionRandomForest = RandomForest.predict (img_test)\n",
        "accuracy_score(predictionRandomForest, label_test)\n",
        "#0.5870646766169154\n",
        "predictionRandomForestDream = RandomForest.predict (Dream)\n",
        "accuracy_score(predictionRandomForestDream, label_test)\n",
        "#0.46766169154228854"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74e1cfb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c4b64efb911801f8de3b008343eb6f60",
          "grade": false,
          "grade_id": "CreateVoting",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a74e1cfb"
      },
      "source": [
        "### Voting Ensemble \n",
        "\n",
        "A **Voting Ensemble** classifier \"*combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels*\".\n",
        "\n",
        "Using **scikit-learn**, create two **Voting Ensemble Classifiers** (*hard voting* and *soft voting*) consisting of the models created in the previous sections (**Evaluating Individal Models**, etc.):\n",
        "* SVM classifier\n",
        "* decision tree classifier\n",
        "* Random Forest classifier\n",
        "\n",
        "Use the default parameters for both *hard voting* and *soft voting* classifiers.\n",
        "\n",
        "Code examples for implementing a **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier).\n",
        "API information on **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier).\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code to create a Voting Ensemble classifier below.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a78f8a",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dd735b4f88ccc27ab48d192456f25df0",
          "grade": true,
          "grade_id": "Voting-Code",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "08a78f8a",
        "outputId": "8da2269b-9540-4209-c925-7cc40fa3b553"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'DecTree' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13116/1952288207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvmEn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvmEn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Decision Tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Random Forest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'DecTree' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "svmEn = svm.SVC(probability = 1)\n",
        "models = [('SVM', svmEn), ('Decision Tree', DecTree), ('Random Forest', RandomForest)]\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "EnsembleSoft = VotingClassifier(estimators = models, voting = 'soft')\n",
        "EnsembleHard = VotingClassifier(estimators = models, voting = 'hard')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b91bf89",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "26323ff580bc87e6109c6e9886c47c25",
          "grade": false,
          "grade_id": "EvaluateEnsembles",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "toc-hr-collapsed": true,
        "id": "7b91bf89"
      },
      "source": [
        "# Evaluate Ensembles\n",
        "\n",
        "Models will be *trained* on the **training data**.\n",
        "\n",
        "Two *separate evaluations* will be performed:\n",
        "* ensemble model will be evaluated on the **original test data**\n",
        "* ensemble model will be evaluated on the **transformed test data**\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>WRITE CODE</h4>\n",
        "    Write the code below to evaluate the ensembles on the test data.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1f1428",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aad1e29819351e4e5051977fc9a69794",
          "grade": true,
          "grade_id": "EvaluateEnsembles-Code",
          "locked": false,
          "points": 10,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dd1f1428"
      },
      "outputs": [],
      "source": [
        "EnsembleSoft.fit(img_train,label_train)\n",
        "predictionSoft = EnsembleSoft.predict(img_test)\n",
        "\n",
        "accuracy_score(predictionSoft, label_test)\n",
        "#0.48756218905472637\n",
        "\n",
        "EnsembleHard.fit(img_train,label_train)\n",
        "predictionHard = EnsembleHard.predict(img_test)\n",
        "accuracy_score(predictionHard, label_test)\n",
        "#0.572139303482587\n",
        "\n",
        "predictionSoftDream = EnsembleSoft.predict(Dream)\n",
        "accuracy_score(predictionSoftDream, label_test)\n",
        "#0.5323383084577115\n",
        "predictionHardDream = EnsembleHard.predict(Dream)\n",
        "accuracy_score(predictionHardDream, label_test)\n",
        "#0.46766169154228854"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af7fcb3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e9667edc3a174becc395d1b5dcb8ee8e",
          "grade": false,
          "grade_id": "Discussion",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "toc-hr-collapsed": true,
        "id": "6af7fcb3"
      },
      "source": [
        "# Discussion Of Results \n",
        "\n",
        "Discuss the results (using charts and graphs where possible).\n",
        "Compare the performance of the various models.\n",
        "Was the performance what you expected?\n",
        "\n",
        "Which system performed best? Why?\n",
        "Which system had the worst performance? Why?\n",
        "\n",
        "Provide some ideas to try that could improve the performance of the models (i.e., *Future Work*).\n",
        "\n",
        "<div class=\"alert alert-danger\">\n",
        "    <h4>DISCUSSION</h4>\n",
        "    <p>Provide your <strong>Discussion Of Results</strong> below. Use visual elements where possible.</p>\n",
        "    <p>Feel free to include both <em>Markdown</em> cells and <em>Code</em> cells where necessary.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d28cea-fcbe-4308-8334-f639544c1e3c",
      "metadata": {
        "id": "70d28cea-fcbe-4308-8334-f639544c1e3c"
      },
      "source": [
        "Compare the performance of the various models.\n",
        "\n",
        "1. SVM Normal [0.5771144278606966] vs SVM Dream [0.46766169154228854]\n",
        "\n",
        "2. Decision Tree Normal [0.4925373134328358] vs Decision Tree Dream [0.5323383084577115]\n",
        "\n",
        "3. Random Forest Normal [0.5870646766169154] vs Random Forest Dream [0.46766169154228854]\n",
        "\n",
        "4. Ensemble Soft Voting - SVM, Decision Tree, Random Forest - Normal [0.48756218905472637] , Dream [0.5323383084577115]\n",
        "\n",
        "5. Ensemble Hard Voting - SVM, Decision Tree, Random Forest - Normal [0.572139303482587], Dream [0.46766169154228854]\n",
        "\n",
        "Using Dreamify on the datasets might have changed the images a lot in visual sense, however, in pixels it \n",
        "changesonly by a few values here and there and there are no significant changes.\n",
        "\n",
        "SVM normal seems to work at par with the Random Forest having best accuracy out of all.\n",
        "\n",
        "Decision Tree Dream unexpectedly performs better on DeepDream than the normal one. \n",
        "\n",
        "Ensemble Hard voting decides the voting class on basis on output classes of the 3 models. An ensemble model is \n",
        "theoretically better in some cases and it works on consensus of the outputs of all 3 models it was fed. \n",
        "\n",
        "Ensemble Soft does not exactly outputs the class value of to the data, it gives a predicted probability function \n",
        "for the classifier. It is recommended to use only when the models are well calibrated. Hard seems to have performed \n",
        "better in overall sense, because because of SVM and Random Forest performing better\n",
        "on the normal dataset as individual models, having low scores in the transformed section would be due \n",
        "SVM and Random Forest performing badly on the Deep Dream. It basically took the average of all 3 models and \n",
        "computed an ensemble prediction. We can see the values are equally bad for svm and randomforest on deepdream and \n",
        "that is what Ensemble Hard shows us. \n",
        "\n",
        "I actually expected SVM would perform better than random forest due to its\n",
        "proficiency in binary class systems while forests work better for \n",
        "multiclass problems. Random Forest would've worked even better if their were some\n",
        "catergorical features.\n",
        "\n",
        "Decision Trees can easily overfit and that's probably one of the reason's \n",
        "its normal score is so low. I am not entirely sure why decision tree performed better on dream data. I did not expect it would perform best \n",
        "on dream data when its normal score is not par with the other models that are better suited to this problem.\n",
        "\n",
        "We can use accuracy_score since there isn't a majority class here. A confusion matrix was also an option but since it wasn't expected, I just used\n",
        "the accuracy_score metric.\n",
        "\n",
        " I also managed to run a single layer KNN on a sequential model.\n",
        " ![image.png](attachment:64d095cd-769d-41c5-9e12-f420a969c7de.png)\n",
        " The accuracy that provided me was way better.\n",
        " \n",
        " Tutorial  https://www.youtube.com/watch?v=YrMy-BAqk8k&t=767s\n",
        "\n",
        "I think one of the deciding factors to performance improvement was the limitation of 1000 images and the lack of better models. Our computers arent powerful enough to compress and train large amount of data. Especially in visual ML training model a lot would depend on the amount of data and the configuration of the models. The more sensitive the models are, the better they would likely perform.\n",
        "It would be better to go through the data to get only the kind of images that really really improve the learning curve of the model. I also think the models we used were not especially equipped to deal with a problem like image classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9318b2b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d8bf01bef78e1a2dacdbba4f2d1e7454",
          "grade": false,
          "grade_id": "cell-0bcc5e15e720751a",
          "locked": true,
          "points": 40,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "c9318b2b"
      },
      "source": [
        "### BEGIN ANSWER\n",
        "\n",
        "### END ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17666739-744b-4cbf-9f9d-5eb8b0e5cd99",
      "metadata": {
        "id": "17666739-744b-4cbf-9f9d-5eb8b0e5cd99"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "Coding_Assign2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}